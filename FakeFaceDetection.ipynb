{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Fake Face Detection\n",
    "Andrew Brown - 20070987 - 17amb@queensu.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My understanding of the project:\n",
    "Input: a SET of 3 face images (left, center, right), the set is either all REAL or all FAKE\n",
    "Output: predict if the entire set is real or fake\n",
    "\n",
    "Method:\n",
    "1. haar-cascade detection to isolate the face in each image, crop this image\n",
    "2. Using SIFT, match the cropped image with the left and right (take note of how many matches) \n",
    "if there are low matches, this is an indicator the image is REAL \n",
    "high matches indicate FAKE because the planar face allows for it\n",
    "3. Take homography and perspective transform of the center image to the left and right \n",
    "if we are not able to find a match ... suggestes real image since we could not transform to the non planar destination\n",
    "\n",
    "Assumptions:\n",
    "1. the images are organized as (n{C}, n{L}, n{R} ... ) for reading in images i am using the letters {} to determine which image it is\n",
    "2. Dataset was missing 1Lr (i duplicated 12Lr and made it 1Lr for completeness)\n",
    "3. if a center image isnt detected properly using haar cascades (for image cropping) then the entire set must be discarded, or fixed\n",
    "\n",
    "Editing comment for github exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "REAL_FACES_DIR = 'C:\\\\Users\\\\prof.brown\\\\Desktop\\\\OneDrive\\\\QueensUniversity\\\\FourthYear\\\\FirstSemester\\\\ELEC474\\\\Project_Brown\\\\real'\n",
    "FAKE_FACES_DIR = 'C:\\\\Users\\\\prof.brown\\\\Desktop\\\\OneDrive\\\\QueensUniversity\\\\FourthYear\\\\FirstSemester\\\\ELEC474\\\\Project_Brown\\\\fake'\n",
    "# Paths will need to change root directory\n",
    "\n",
    "# paths have double backslash for windows dir\n",
    "# discovered_ratio = 0.00015 # anything below is real\n",
    "discovered_ratio = 0.00034\n",
    "answer = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "#answer = [1, 1, 1, 1, 1, -1, -1, -1, -1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cascade_crop(img_path):\n",
    "    \"\"\"\n",
    "    Using a haar-cascade, iterate through each center image, detect a face and crop the image\n",
    "    \"\"\"\n",
    "    # Load the cascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    # Read the input image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # handles pyplot printing issues\n",
    "    # Convert into grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4, cv2.CASCADE_FIND_BIGGEST_OBJECT)\n",
    "    \n",
    "    try:\n",
    "        (a, b, c, d) = faces[0]\n",
    "    except:\n",
    "        print(\"unable to find any faces in center image: \")\n",
    "        print(img_path)\n",
    "        return -1\n",
    "    \n",
    "    # only take the biggest rectangle -> case handling if more than one detection\n",
    "    \n",
    "    max_area = 0\n",
    "    for face in faces:\n",
    "        area = face[2] * face[3]  # w * h\n",
    "        if area > max_area:\n",
    "            biggest_face = [face]  # [] allows it to be unpacked\n",
    "    \n",
    "    # Draw rectangle around the faces\n",
    "    \n",
    "    (x, y, w, h) = biggest_face[0]\n",
    "    crop_img = gray[y:y+h, x:x+w]\n",
    "    # cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    # Display the output\n",
    "    #plt.imshow(crop_img, cmap='gray')\n",
    "    #plt.show()\n",
    "    return crop_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_imgs(DIR, DIR2):\n",
    "    \"\"\"\n",
    "    Going through two directories DIR, DIR2 (real and fake respectively)\n",
    "    load each file name to be tested\n",
    "    \"\"\"\n",
    "    center = []\n",
    "    left = []\n",
    "    right = []\n",
    "    for filename in os.listdir(DIR):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # if the file is a picture\n",
    "            if 'C' in filename:  # center\n",
    "                center.append(os.path.join(DIR, filename))\n",
    "            elif 'L' in filename:  # left\n",
    "                left.append(os.path.join(DIR, filename))\n",
    "            elif 'R' in filename:  # right\n",
    "                right.append(os.path.join(DIR, filename))\n",
    "            else:\n",
    "                pass\n",
    "    for filename in os.listdir(DIR2):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # if the file is a picture\n",
    "            if 'C' in filename:  # center\n",
    "                center.append(os.path.join(DIR2, filename))\n",
    "            elif 'L' in filename:  # left\n",
    "                left.append(os.path.join(DIR2, filename))\n",
    "            elif 'R' in filename:  # right\n",
    "                right.append(os.path.join(DIR2, filename))\n",
    "            else:\n",
    "                pass    \n",
    "    return center, left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(img1, img2):\n",
    "    \"\"\"\n",
    "    function to return key points, descriptors, and Lowe's ratio matches\n",
    "    Assuming images are passed in as grayscale\n",
    "    \"\"\"    \n",
    "    # instantiate feature detector SIFT\n",
    "    sift = cv2.SIFT_create()  \n",
    "    img1_keypoints, img1_descriptors = sift.detectAndCompute(img1, None)\n",
    "    img2_keypoints, img2_descriptors = sift.detectAndCompute(img2, None)\n",
    "        \n",
    "    # Create brute force matches\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # match descriptors\n",
    "    matches = bf.knnMatch(img1_descriptors, img2_descriptors, k=2)\n",
    "\n",
    "    # draw the matches\n",
    "    # img = cv2.drawMatchesKnn(img1, img1_keypoints, img2, img2_keypoints, matches, None)\n",
    "    # cv2.imshow(\"KNN matches\", img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    # lowe's ratio \n",
    "    good = []\n",
    "    good_distance = []\n",
    "    lowes = []  # to be returned for affine transformation\n",
    "    distances = []\n",
    "    \n",
    "    #print(len(matches))\n",
    "    #print(\"ratio: \" + str((len(matches)/pix) * 100))\n",
    "    \n",
    "    for m,n in matches:\n",
    "        distances.append(m.distance)\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good.append([m])  # for drawing\n",
    "            lowes.append(m)  # return to affine transformation\n",
    "    \n",
    "    # draw the matches\n",
    "    #img = cv2.drawMatchesKnn(img1, img1_keypoints, img2, img2_keypoints, good, None)\n",
    "    #cv2.imshow(\"Lowe's Matches\", img)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    return img1_keypoints, img1_descriptors, img2_keypoints, img2_descriptors, lowes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_exploration(img1, img2, pix):\n",
    "    \"\"\"\n",
    "    Identical to matching SIFT function but returns amount of matches for calculating ratio\n",
    "    \"\"\"    \n",
    "    # instantiate feature detector SIFT\n",
    "    sift = cv2.SIFT_create()  \n",
    "    img1_keypoints, img1_descriptors = sift.detectAndCompute(img1, None)\n",
    "    img2_keypoints, img2_descriptors = sift.detectAndCompute(img2, None)\n",
    "        \n",
    "    # Create brute force matches\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # match descriptors\n",
    "    matches = bf.knnMatch(img1_descriptors, img2_descriptors, k=2)\n",
    "    \n",
    "    # lowe's ratio \n",
    "    good = []\n",
    "    good_distance = []\n",
    "    lowes = []  # to be returned for affine transformation\n",
    "    distances = []\n",
    "    \n",
    "    for m,n in matches:\n",
    "        distances.append(m.distance)\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            good.append([m])  # for drawing\n",
    "            lowes.append(m)  # return to affine transformation\n",
    "    #img = cv2.drawMatchesKnn(img1, img1_keypoints, img2, img2_keypoints, good, None)\n",
    "    #cv2.imshow(\"Lowe's Matches\", img)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    length = len(good)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(reference, test):\n",
    "    \"\"\"\n",
    "    Function to apply perspective transforms to 4 corners of reference image\n",
    "    \"\"\"    \n",
    "    rows,cols = test.shape\n",
    "    # reference is the cropped image\n",
    "    try:\n",
    "        kp1, ds1, kp2, ds2, lowe_matches = matching(reference, test)\n",
    "        ref_pts = np.float32([kp1[m.queryIdx].pt for m in lowe_matches]).reshape(-1, 1, 2)\n",
    "        img_pts = np.float32([kp2[m.trainIdx].pt for m in lowe_matches]).reshape(-1, 1, 2)\n",
    "        homo_trans_mat, not_used_mask = cv2.findHomography(ref_pts, img_pts, cv2.RANSAC,5.0)  # values from opencv documentation\n",
    "        four_corners = np.array([[0,0], [reference.shape[0], 0], [reference.shape[0], reference.shape[1]], [0, reference.shape[1]]], np.float32)\n",
    "        four_corners = four_corners.reshape(-1, 1, 2).astype(np.float32)\n",
    "        #print(four_corners)\n",
    "        #print(homo_trans_mat)\n",
    "    except:\n",
    "        return 1  # failed, image is real\n",
    "    \n",
    "    # checking to see if problem with fundamental matrix or four corners\n",
    "    try:\n",
    "        dst = cv2.perspectiveTransform(four_corners, homo_trans_mat)\n",
    "        #print(dst)\n",
    "    except:\n",
    "        return 1  # failed, image is real\n",
    "   \n",
    "    #dst = cv2.warpPerspective(reference, homo_trans_mat, (rows, cols))\n",
    "    return(clockwise_test(dst))  # check for order of points, if clockwise, image is fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clockwise_test(points):\n",
    "    \"\"\"\n",
    "    Import transformed points and check to see if they make a clockwise or counter clockwise polygon\n",
    "    \"\"\"\n",
    "    running_sum = 0\n",
    "    #print(points.shape)\n",
    "    points = points.reshape(-1, 2)\n",
    "    #print(points)\n",
    "    for i, point in enumerate(points):\n",
    "        try:\n",
    "            x = points[i][1]\n",
    "            y = points[i][0]\n",
    "            x_plusone = points[i+1][1]\n",
    "            y_plusone = points[i+1][0]\n",
    "            #print(x, y, x_plusone, y_plusone)\n",
    "        except:\n",
    "            x_plusone = points[i][1]  # points wrap\n",
    "            y_plusone = points[i][0]  # points wrap\n",
    "        running_sum = running_sum + ((x_plusone - x) * (y_plusone + y))\n",
    "    # print(running_sum)\n",
    "    if running_sum > 0:  # clockwise\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_SIFT_matching(c, l, r, predictions, discovery):\n",
    "    \"\"\"\n",
    "    Function to iterate in parallel fashion\n",
    "    args: c (already in image format), l, r (both l and r are still directory paths to file names)\n",
    "    \n",
    "    Driver code for SIFT matching function. Filters results based on matches/amount of pixels\n",
    "    \"\"\"\n",
    "    match_count = []\n",
    "    pix = []\n",
    "    for center_crop, left_img, right_img in zip(c, l, r):\n",
    "        pix_area = center_crop.shape[0] * center_crop.shape[1]\n",
    "        pix.append(pix_area)\n",
    "        pix.append(pix_area)\n",
    "        \n",
    "        in_left = cv2.imread(left_img)\n",
    "        in_left = cv2.cvtColor(in_left, cv2.COLOR_BGR2GRAY)\n",
    "        count_left = matching_exploration(center_crop, in_left, pix_area)\n",
    "        match_count.append(count_left)\n",
    "        \n",
    "        in_right = cv2.imread(right_img)\n",
    "        in_right = cv2.cvtColor(in_right, cv2.COLOR_BGR2GRAY)\n",
    "        count_right = matching_exploration(center_crop, in_right, pix_area)\n",
    "        match_count.append(count_right)\n",
    "        \n",
    "        if (count_left/pix_area > discovery) and (count_right/pix_area > discovery):  # image should have homography applied\n",
    "            predictions.append(0)  # undetermined\n",
    "            print(\"probably fake, needs homography\")\n",
    "        else:\n",
    "            predictions.append(1)  # real\n",
    "            print(\"predicting real\")\n",
    "    \n",
    "    match_count = np.asarray(match_count)\n",
    "    pix = np.asarray(pix)\n",
    "    \n",
    "    ratios = np.divide(match_count, pix)\n",
    "    # two ratios per each set, if either is less than \n",
    "    \n",
    "    var = np.var(ratios)\n",
    "    sigma = np.std(ratios)\n",
    "    two_sigma = 2 * sigma\n",
    "    \n",
    "    m, b = np.polyfit(pix, match_count, 1)\n",
    "    plt.title(\"pixel count/area vs number of matches\")\n",
    "    plt.scatter(pix, match_count)\n",
    "    \n",
    "    plt.plot(pix, m*pix + b)\n",
    "    plt.show()\n",
    "    \n",
    "    ratio = np.mean(ratios)\n",
    "    print(\"ratio - sigma: \" + str(ratio - sigma))\n",
    "    print(\"ratio: \" + '\\t\\t' + str(ratio))\n",
    "    print(\"ratio + sigma: \" + str(ratio + sigma))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_homography(c, l, r, predictions):\n",
    "    \"\"\"\n",
    "    Function to iterate in parallel fashion\n",
    "    args: c (already in image format), l, r (both l and r are still directory paths to file names)\n",
    "    \n",
    "    Driver code for perspective transform function. Classifies based on four corners transformation\n",
    "    \"\"\"\n",
    "    final_prediction = []\n",
    "    for center_crop, left_img, right_img, prediction in zip(c, l, r, predictions):\n",
    "        if prediction == 1:  # prediction has been determined real, don't need homography\n",
    "            final_prediction.append(1)\n",
    "            continue\n",
    "        in_left = cv2.imread(left_img)\n",
    "        in_left = cv2.cvtColor(in_left, cv2.COLOR_BGR2GRAY)\n",
    "        out_left = perspective_transform(center_crop, in_left)\n",
    "        \n",
    "        in_right = cv2.imread(right_img)\n",
    "        in_right = cv2.cvtColor(in_right, cv2.COLOR_BGR2GRAY)\n",
    "        out_right = perspective_transform(center_crop, in_right)\n",
    "        if (out_left > 0) and (out_right > 0):\n",
    "            final_prediction.append(-1)\n",
    "            print(\"fake image\")\n",
    "        else:\n",
    "            final_prediction.append(1)\n",
    "            print(\"real image\")\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(ans, pred):\n",
    "    \"\"\"\n",
    "    input: bit vector of answers and predictions \n",
    "    create confusion matrix based off predictions\n",
    "    1 = real image\n",
    "    -1 = fake image\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for a, p in zip(ans, pred):\n",
    "        if a == 1 and p == 1:\n",
    "            tp = tp + 1\n",
    "        elif a == -1 and p == 1:\n",
    "            fp = fp + 1\n",
    "        elif a == -1 and p == -1:\n",
    "            tn = tn + 1\n",
    "        elif a == 1 and p == -1:\n",
    "            fn = fn + 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(str(tn) + '\\t' + str(fp))\n",
    "    print(str(fn) + '\\t' + str(tp))\n",
    "    print(\"precision: \" + str(precision))\n",
    "    print(\"recall: \" + str(recall))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_unknown, l_unknown, r_unknown = parse_imgs(REAL_FACES_DIR, FAKE_FACES_DIR)\n",
    "#c_fake, l_fake, r_fake = parse_imgs(FAKE_FACES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_unknown_crop = []\n",
    "predictions = []\n",
    "for image in c_unknown:\n",
    "    c_unknown_crop.append(cascade_crop(image))\n",
    "#for image in c_fake:\n",
    "#    c_fake_crop.append(cascade_crop(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "predicting real\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n",
      "probably fake, needs homography\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjpUlEQVR4nO3deZwU1b338c/PAXFEBRFEZgRBg8QtLJmHJBeNJi6oMUBMVEweo4lGTUzMSiLm3sQkeiUh8Zonm0viNcZdozBRn4tGYxJ3QTYBiagIzCCbIqgjDjPn/lFnoBi6p7unq6u7qr/v16tfU32qquvX1dW/OnPOqWpzziEiIumyS7kDEBGR6Cm5i4ikkJK7iEgKKbmLiKSQkruISAopuYuIpJCSe0zM7CgzWxrB6zxqZudFEZNUHjM7x8weK+P2v2xma8zsLTPbp1xxdGZmN5rZ5eWOI0mU3GPinPunc25EueOImpldZmY3Zyjf1czWm9ke5YhLCmdmPYGrgBOcc3s45zaUeHvLzey4Um6jmim5S6l8FJjnnHurkJXMrEeJ4qk63diXA4HdgEUlCEdipuQeIV8TmWpmi83sDTP7bzPbzc87xsxW+emDzOx1Mxvjn9f5Wu4x/vmHzewJM9toZvM7yvPYfo2ZXWpmL5nZZjObY2aD/bx/M7NnzexN//ffOsV9XOj5ttq4mQ01M2dmZ5vZCh/n9/28E4FLgTP8v/HzQ+GcDDzgl/uCmS3xMb1sZheEtnWMma0ys++Z2WvAf5vZLmZ2iX8fG8zsTjPrF1rnLjN7zb+Xf5jZYVn2x2Qzm92p7Jtm1uinT/af1WYzazKz72R5nXPM7DEz+7n/XF8xs5MK3H9fMLOVfv0Lzez/mNkC/xn/eudN2q/8+3vBzI4NzehjZn8ws9U+5svNrCYU5+Nm9l9m9jpwWYb30svMrjazZv+42pcdDHQ0G240s0cyrFvQe/HH+SP+M1xvZreYWV8/70/AEOAv/tj5ri8/MnTsrzSzc0Ih7G1m9/vP62kzOyi0rfeb2UMWfK+WmtnpoXl5fc6p45zTI6IHsBx4HhgM9AMeBy73844BVoWW/RKwBNgdmAX83JfXAxsIkuMuwPH++QA//1HgvCzbnwIsBEYABowE9vGxvAGcBfQAzvTP9wnFfVzodS4DbvbTQwEHXA/U+tfcAhzSedlOsbwAjPDTnwAO8jEdDbwDjAntl63AT4FefhvfAJ4C9vdl1wK3hV77i8Ceft7VBP8hZNofuwObgeGhsmeByX56NXCUn967I6YMr3MO0Oo/sxrgy0AzYAXsv2sIasUnAO8CM4B9/ee9Fjg6tK2twDeBnsAZwJtAPz9/ht8fvf36zwAXdFr3a/5zrs3wXn7s9+2+wADgCeAnnWLtkWU/FPpe3kdw/Pby2/oHcHWn70t4vw3xn9eZ/r3vA4zy824EXgfG+vd2C3C7n9cbWAl8wc8bA6wHDivkc07bo+wBpOnhD9YLQ89PBl7y08cQSu6+rJEgGS8Aevmy7wF/6rTcLOBsP/0o2ZP7UmBihvKzgGc6lT0JnBOKO1dy2j80/xm2J8hty4bmH9jxvrPEOQP4emi/vAfsFpq/BDg29HwQQXLdKekAfX18fbJs62bgB356uE8eu/vnK4ALgL1yfK7nAMtCz3f329yvgP1XH5q/ATgj9PzPwDdC29p24gjt77MImk22EEraBInwb6F1V+R4Ly8BJ4eejweWd4o1V3LP671kWH8SMLfT9yW836YC92ZZ90bg952+Wy/46TOAf3Za/lrgh4V8zml7qFkmeitD068CdV0sez1wOPAr59wWX3YAcJr/t3SjmW0EjiRIcLkMJvjydlbnYwl7laCmla/XQtPvAF11lH4C3yQDYGYnmdlT/l/mjQRfzP6h5dc5594NPT8AuDf0/pcAbcBAC5qepvkmm00ECYJOrxd2K0ECBPgsMMM5945//mkfy6tm9ncz+0gX72nb+w+tX0hn8ZrQdEuG5+HXanI+K3kdx9EBBDXa1aF9cy1BrblD+PjLpPOxkOsYzSSv92Jm+5rZ7b4pZBPBiTbb5wTZj98O2Y7BA4APdfrOfA7Yz88v5HNODSX36A0OTQ8hqIXtxIJRJFcDfwAus+1tyisJau59Q4/ezrlpeWx7JUHzR2fNBF+AsCFAk59+m6A22mE/8pfptqInA/dD0MZLUJv7OTDQOdeXIPFbF6+xEjip0z7YzTnXRJCgJwLHAX0IapN0er2wB4H+ZjaKIMnfum2jzj3rnJtIkBxnAHfm8X4zKWb/ZVJvZuH303EcrSSoufcP7Ze9nHPhPodct3ntfCxkPUYjcKWP5wPOub2A/0vuzz3T8ZvLSuDvnY6XPZxzX4ZIP+dEUXKP3kVmtr9P1pcCd2RZ7pfAHOfceQSJ8BpffjPwSTMb72upu1nQ6bh/Htv+PfATMxtugQ9YMFb5AeBgM/usmfUwszOAQ4H7/HrzgMlm1tPMGoDPFPB+1wBDzWwXADOrJWgXfdTP35WgzXUdsNWCjsgTcrzmNcAVZnaAf80BZjbRz9uTIMFtIEio/9nVCznntgJ3A9MJ+h4e8q+5q5l9zsz6OOdagU0E/x10xzy6v/8y2Re42L/eacAhwAPOudUEJ6tfmNleFnQ8H2RmRxfw2rcB/+73aX/gBwTHXCnsCbxF0EFbT9AnFLaGoAmvwy3AcWZ2uj9O9/En5VzuIzi+z/L7rKfv5D0k4s85UZTco3crwRfwZf/Y6cILn6hOBC70Rd8CxpjZ55xzKwlqppcSJMSVBF+KfD6rqwhqJQ8SHMR/IGif3QCcAnybICl+FzjFObfer/cfBDWmN4AfEard5uEu/3eDmT0HHAs82dHM4pzbDFzs43qDoObdmOM1f+mXedDMNhN0AH7Iz7uJoCmhCVjs5+VyK0FN/y6f7DucBSz3TQYXEtQsu6OY/ZfJ0wT9A+uBK4DPuO1jzj9PcMJc7Ld3N/k12XW4HJhN0M+zEHiODMdoRH5E0Ln5JkEF5p5O868kONFsNLPvOOdWEPzX922CztN5BB34XfLH2AnAZIL/Ql5jewc9RPc5J0pHb79EwMyWE3R2/rXcsZSLmf0WeN4599tyxyJSzXTBiERtHvCXcgchUu2U3CVSzrnryh2DiKhZRkQkldShKiKSQhXRLNO/f383dOjQcochIpIoc+bMWe+cG5BpXkUk96FDhzJ79uzcC4qIyDZm1vnK823ULCMikkJK7iIiKaTkLiKSQkruIiIppOQuIpJCFTFaRiQNZsxtYvqspTRvbKGuby1Txo9g0uhCbpkvEh0ld5EIzJjbxNR7FtLSGtxNtmljC1PvWQigBC9loWYZkQhMn7V0W2Lv0NLaxvRZS7OsIVJaSu4iEWje2FJQuUipKbmLRKCub21B5SKlpuQuEoEp40dQ27Nmh7LanjVMGT+iTBFJtVOHqkgEOjpNNVpGKoWSu0hEJo2uVzKXiqFmGRGRFFJyFxFJoZzJ3cwGm9nfzGyJmS0ys6/78n5m9pCZvej/7h1aZ6qZLTOzpWY2vpRvQEREdpZPzX0r8G3n3CHAh4GLzOxQ4BLgYefccOBh/xw/bzJwGHAi8Fszq8n4yiIiUhI5k7tzbrVz7jk/vRlYAtQDE4E/+sX+CEzy0xOB251zW5xzrwDLgLERxy0iIl0oqM3dzIYCo4GngYHOudUQnACAff1i9cDK0GqrfFnn1zrfzGab2ex169Z1I3QREckm7+RuZnsAfwa+4Zzb1NWiGcrcTgXOXeeca3DONQwYkPH3XUVEpJvySu5m1pMgsd/inLvHF68xs0F+/iBgrS9fBQwOrb4/0BxNuCIiko98RssY8AdgiXPuqtCsRuBsP302MDNUPtnMepnZMGA48Ex0IYuISC75XKE6DjgLWGhm83zZpcA04E4zOxdYAZwG4JxbZGZ3AosJRtpc5Jxr2+lVRUSkZHImd+fcY2RuRwc4Nss6VwBXFBGXiIgUQVeoioikkJK7iEgKKbmLiKSQkruISAopuYuIpJCSu4hICim5i4ikkJK7iEgKKbmLiKSQkruISAopuYuIpJCSu4hICim5i4ikkJK7iEgKKbmLiKSQkruISAopuYuIpJCSu4hICim5i4ikkJK7iEgKKbmLiKSQkruISAr1KHcAImkxY24T02ctpXljC3V9a5kyfgSTRteXOyypUkruIhGYMbeJqfcspKW1DYCmjS1MvWchgBK8lIWaZUQiMH3W0m2JvUNLaxvTZy0tU0RS7ZTcRSLQvLGloHKRUlNyF4lAXd/agspFSk3JXSQCU8aPoLZnzQ5ltT1rmDJ+RJkikmqnDlWRCHR0mmq0jFQKJXeRiEwaXa9kLhVDzTIiIimkmruISBmU+qI3JXcRkZjFcdGbmmVERGIWx0VvSu4iIjGL46I3JXcRkZjFcdGbkruISMziuOhNHaoiIjGL46K3nMndzG4ATgHWOucO92WXAV8C1vnFLnXOPeDnTQXOBdqAi51zsyKLVkQkJUp90Vs+zTI3AidmKP8v59wo/+hI7IcCk4HD/Dq/NbOaDOuKiEgJ5Uzuzrl/AK/n+XoTgdudc1ucc68Ay4CxRcQnIiLdUEyH6lfNbIGZ3WBme/uyemBlaJlVvkxERGLU3eT+O+AgYBSwGviFL7cMy7pML2Bm55vZbDObvW7dukyLiIhIN3UruTvn1jjn2pxz7cD1bG96WQUMDi26P9Cc5TWuc841OOcaBgwY0J0wREQki24ldzMbFHr6KeB5P90ITDazXmY2DBgOPFNciCIiUqh8hkLeBhwD9DezVcAPgWPMbBRBk8ty4AIA59wiM7sTWAxsBS5yzrVleFkpQKnvHici6WPOZWwSj1VDQ4ObPXt2ucOoSJ3vHgfBlWxXnnpE1SR4ndxEMjOzOc65hkzzqv4K1UpPHF3dPa6S4iyVOG6NKpJGVZ3ck5A44rh7XCUr5cmt0k/sIsWo6huHxXFP5WLFcfe4Slaqk1vHib1pYwuO7Sf2GXObinpdkUpR1ck9zlrxjLlNjJv2CMMuuZ9x0x7JO4nEcfe4Slaqk1s5TuzdPQZEuqOqk3tcteJiaomTRtdz5alHUN+3FgPq+9ZWVWdqqU5ucTd36T8FiVtVt7lPGT8i40iUqGvFxbYbl/rucZWsVLdGretbS1OGRF6q5q5q7xiX+FV1co/jnsqgTtFileLkFteJvYOOAYlbVTfLxKXaO0UrUdzNXToGJG5VXXOPayjklPEjmHL3fFrbtl8w1rPGEtMpmtYhg3E2d8X9n4JIVSf3WNtBO18IXP4Lg/NSCdcCpOHkElcToEiHqk7ucbWDTp+1lNb2HbN5a7tLRGdauTsCK+HkEpVq7hiX+FV1m3tc7aBJ7kwrd+xJuNBMpBJVdXKP6wKhJHemlTv2cp9cRJKqqpN7XCMmknyVabljL/fJRSSpqrrNHeJpB01yZ1q5Y9coE5Hu0f3cs0jDCI200Gchkpnu516gNI3QKEalJFWNMhEpXFW3uWejERq60ZVI0im5Z6ARGjrBiSSdknsGGqFBxjsmdlUuIpVFyT2Dcg//qwQ1ZlnnqWlGpPKpQzWDcg//qwRtXYyiqsbOZZGkUXLPotpHaNRn+TEL0I9MlEqljE6SdFCzjGSUqWkqrJo6l+Og0UkSNSV3yajj1gzZ2t6rqXM5DhqdJFFTcpesJo2u5xenj6z6zuU4aPitRE3JXboU98/RVSsNv5WoqUM1C3VubVftnctx0A3SJGpK7hno3jLVoZJO4Bp+W31KffzprpAZjJv2SMZhgPV9a3n8ko+XISKJWucTOAQ1ZTU5SRyiOv66uiuk2twzUOdW+ml0ipTLC69t4t9nPF/y40/NMhnUZbmAR51b6aETuJTa2s3vcv+C1TTOb2buio15rRPl8afknoE6t9JPJ3CJyrutbTy8ZC0z5zXx4OI1OZcf0m933nj7PTZv2brTvCiPPyX3DNS5lX46gUuh2tsdc1a8QeO8ZmbOa2LTuzsn57BePXZh4qg6Jo6q58MH7kPNLtsvCMzW5h7l8afknoWG/6WbTuDSleXr36ZxfjON85tZtvatnMsfM2IAE0bWcfyhA9lzt545l4/j+NNoGRGpWm++08r/LFrNzHnNPPHShpzLHzpoLyaOquOUkXXUV0ATnn5DVUSqWmtbO/98cR2N84LaeHuOOm3/PXZlwsh6Jo6q4wP798G6+H2DSqXkLiKp4ZxjUfMmGucH7eJrNm3Juc4pHxjEhJF1HD1iAL16ZL8TatIouYvEpJKuiE2D1958l/sWBDXxBavezLn82GH9mDiqjpMOH0S/3rvGEGF55UzuZnYDcAqw1jl3uC/rB9wBDAWWA6c7597w86YC5wJtwMXOuVkliVwkQXRLi+57572tPLR4DY3zmnn4hbU5lx/WvzefHFnHhJF1vG/fPWKIsDLlU3O/Efg1cFOo7BLgYefcNDO7xD//npkdCkwGDgPqgL+a2cHOuTZEqlhXV8QquQfa2x3PLH+dmfOaaZzXxNvvdZ02eu9aw4RR9UwYWcfYYf12GGooeSR359w/zGxop+KJwDF++o/Ao8D3fPntzrktwCtmtgwYCzwZUbwiiZTPFbHV1Gzz0rq3aJzXzF/mN/Py+rdzLn/s+/dlwqg6jjtkIL17qTU5H93dSwOdc6sBnHOrzWxfX14PPBVabpUv24mZnQ+cDzBkyJBuhlEdqulLn1a5rohNa7PNG2+/xwPPB0MNn3nl9ZzLH1Hfhwkj6zhl5CAG9Sn/UMMki/oUmOn/ooyDjpxz1wHXQTDOPeI4UiOtX/pqk+uK2KQ322zZ2sY//rWexvlBbTyXgXv1YqJvUjmsbq9EDjWsdN1N7mvMbJCvtQ8COno5VgGDQ8vtD+T+pCWrpH/pJZDrisSk3MjMOcdzK97g/gWv0Ti/mfVvdT3U0AwmjKxj4qg6jnzfAHbtoRvRxqW7yb0ROBuY5v/ODJXfamZXEXSoDgeeKTbIapaUL73k1tUtLSrxRmZzXn2d82+aw4a338tr+X87aB8mjKzjxMP3o+/u6R9qWOnyGQp5G0HnaX8zWwX8kCCp32lm5wIrgNMAnHOLzOxOYDGwFbhII2WKU4lfeoleOW9ktnbTu3z7rvn888X1ea/zreMP5pMj6xjWv3cJI5Ni5DNa5swss47NsvwVwBXFBCXb6e6F1SGOG0m9t7Wdq//6L3776EsFrTdl/AguPPogDTVMGI0pqnC6e2H1iPJOpA8sXM1XbnmuoHVOPmI/rph0BHtXwdWb1UDJPQF0+2HJ5l9rNvOVW57L67a0HQb3q+V3n/sgh9f3KWFkUm5K7iIJsOndVn44cxH3zm0qaL2rTh/Jp0bXa6hhFVJyF6kg7e2O3/39pYJ/KPmL44bx3RNHsFvP9NzVUIqj5C5SJrMWvcYFf5pT0Dpjh/XjqtNHsv/eu5coKkkLJXeREnu+6U1O+dVjBa3Te9carvt8A+Pe179EUUnaKbmLROStLVsZ8+OHeK+tvaD1vjhuGN//xCEaaiiRUnIXKZBzjil3L+DuOasKXveJSz6uC9AkFkruIl24e84qvnPX/ILXu/7zDRx/6MASRCSSHyV3EWD5+rc55uePFrzemWOHcOWpR0QfkEiRlNylqrS2tTPmxw+xecvWgtd9/kfj2UM/FCEJoSNVUuvy+xbz+8deKXi9GReNY9TgvtEHJBIjJXdJvCeWreezv3+64PW+c8LBfPXjw0sQkUj5KblLYrz+9nuM+clDBa934IDePPTNozXUsEj6ucdkUXKXiuOc4zPXPMmcV98oeN2nph7Lfn12K0FU1U0/95g8Su5SVn96cjn/MXNRwetde9YHGX/YfiWISDLRzz0mj5K7xGL+yo1M/M3jBa936ph6rjp9VPQBSUH0c4/Jo+QukXp7y1YO++Gsbq275McnUrur7mpYifRzj8mj5C7dNvaKv7J285aC17v7wo/QMLRfCSKSUtHPPSaPkrvkdMNjr/Dj+xYXvN75Hz2QS08+ZKfyGXOb+Prtj2jURYLo5x6TR8ldtmna2MK4aY90a92X//NkdsljqKFGXSSXfu4xWZTcq1B7u+PASx/o1rr//O7HGNyv+z8UoVEXIvFQck+5yxoXceMTywte75eTRzFxVPTJVqMuROKh5J4ST7+8gTOue6rg9Y58X39uPu9DJYgoM426EImHknvCvPPeVg79QfeGGr7wkxPL/gPKGnUhEg8l9wp28W1zaZzfXPB6933tSA6v71OCiIqnURci8VByrwBPvbyByd1oUrny1CM4c+yQEkRUWhp1IVJ6Su4x2vDWFo762d9457223AuHHDW8Pzd9cSxmuquhiORHyb0E2tsdNzz+Cpffv6Tgdef/4AT67N6zBFGJSDVRci/Sky9t4Es3zeatAn+27f6Lj+SwuspsFxeR5FNyz1Pzxha+dec8nnr59bzX2a3nLlz/+QaOGj6ghJGJiOxMyb2Td/3Vkn8o8Lc3p570fs476kD92o+IVISqTu4vvLaJmfOa+d2jL+W9zoSRdfxk4uFqFxeRilYVyX3t5ne5f8FqGuc3M3fFxrzWOXBAb37z2TEcMmiv0gYnIlICqUru77a28fCStcyc18SDi9fkXH5wv1omjKzjkyPreP9+SuIikh6JTu7t7Y4Lbp7DQzkSea8euzBxVB0TRtbz4QP70aNml5giFBEpj0Qn940trTsl9qMPHsDEUXUcf+hA9txN7eIiUp0Sndz79d417x+JEBGpJolvn1BiFxHZWVE1dzNbDmwG2oCtzrkGM+sH3AEMBZYDpzvn3iguTBERKUQUNfePOedGOeca/PNLgIedc8OBh/1zERGJUSmaZSYCf/TTfwQmlWAbIiLShWKTuwMeNLM5Zna+LxvonFsN4P/um2lFMzvfzGab2ex169YVGYaIiIQVO1pmnHOu2cz2BR4ysxfyXdE5dx1wHUBDQ4MrMg4REQkpqubunGv2f9cC9wJjgTVmNgjA/11bbJAiIlKYbid3M+ttZnt2TAMnAM8DjcDZfrGzgZnFBikiIoUppllmIHCv/+m3HsCtzrn/MbNngTvN7FxgBXBa8WGKiEghup3cnXMvAyMzlG8Aji0mKBERKU7ir1AVEZGdKbmLiKSQkruISAol+q6QItVuxtwmps9aSvPGFur61jJl/Agmja4vd1hSAZTcRRJqxtwmpt6zkJbWNgCaNrYw9Z6FAErwomYZkaSaPmvptsTeoaW1jemzlpYpIqkkqrmLJFTzxpaCyoulJqBkUc1dJKHq+tYWVF6Mjiagpo0tOLY3Ac2Y2xT5tiQaSu4iCTVl/Ahqe9bsUFbbs4Yp40dEvi01ASWPmmVEEqqjSSSOppK4m4CkeEruIgk2aXR9LO3edX1racqQyEvRBCTRULOMiOQUZxOQREM1dxHJKc4mIImGkruI5CWuJiCJhpK7SIJp7Llko+QuklC6/YB0RcldJIdy1o672nZXY8+V3EXJXaQL5awd59q2xp5LVzQUUqQL5bwyM9e247z9gCSPkrtIF8pZO861bY09l64ouYt0oZy141zbnjS6nitPPYL6vrUYUN+3litPPULt7QKozb0i5dOBpyFw8ZgyfsQO7d4QX+34Y+8fwM1PrchY3kFjzyUbJfcClTqp5tOBpyFw8Zk0up7Zr77ObU+vpM05asz49AfjSah/e2FdQeUiYWqWKUAc97TOpwMv6bdfnTG3iXHTHmHYJfczbtojFX1P8Blzm/jznCbanAOgzTn+PKcplpg1GkaKoeRegDiSaj5f6CR/6ZP2ow/lPJFqNIwUQ8m9AHEk1Xy+0JX6pc+nRp60/zrKeSLVaBgphpJ7AeJIqlPGj6Bnje1Q1rPGdvhCV+KXPt8aedL+6yjniVSjYaQY6lAtQGwjJ1zXzyvx9qv5XgqftB99KOdoGdBoGOk+JfcClCqphkfg7GK2rfOuQ2u72ylJVtqXPt8aebmTZaEq8UQqkg8l9wJFnVQ7D2vsnNg7VGqzRYd8a+RJTJaVdiIVyYeSe5llas7IpFKbLToUUiNXshQpPSX3MsunRp4pSVbaFapJrJGLpFmik3ulJbjuyNacUWNGu3MZ35euUBWRXBKb3KNOcOU6UUwZP4Ipd8+ntW17W3vPGmP6Z0Zm3X4l/kiDTjgilSWx49yjvBimkKsmS3LpfI6hj51V4ljxpF2cJJJ2iU3uUSa4fBNTKS6dnz5rKa3tmYc+ZlOJV6hW4glHpJolNrlHmeDyTUylqJ12JylW4hWqlXjCEalmiU3u4Xta51Pelb6798yrvBS10+4kxUq8LL0STzgi1SyxHapR3us6y3VDO5WX4tL57l6xWWljxTUUUqSylCy5m9mJwC+BGuD3zrlpUb5+lLXoN1ta8yovxaXzaUqKlXbCEalmJUnuZlYD/AY4HlgFPGtmjc65xVFtI8padLkvnVdSFJGolarmPhZY5px7GcDMbgcmApEl9yhr0bp0XkTSplTJvR5YGXq+CvhQeAEzOx84H2DIkCEFbyDKWnSamkZERADMZetNLOZFzU4DxjvnzvPPzwLGOue+lmn5hoYGN3v27MjjEBFJMzOb45xryDSvVEMhVwGDQ8/3B5pLtC0REemkVMn9WWC4mQ0zs12ByUBjibYlIiKdlKTN3Tm31cy+CswiGAp5g3NuUSm2JSIiOyvZOHfn3APAA6V6fRERyS6xtx8QEZHsSjJapuAgzNYBr5Y7jgz6A+vLHUSBkhgzJDPuJMYMyYxbMWd2gHMu4w21KiK5Vyozm51tmFGlSmLMkMy4kxgzJDNuxVw4NcuIiKSQkruISAopuXftunIH0A1JjBmSGXcSY4Zkxq2YC6Q2dxGRFFLNXUQkhZTcRURSqCqSu5ktN7OFZjbPzGb7sn5m9pCZvej/7h1afqqZLTOzpWY2PlT+Qf86y8zs/5mZ+fJeZnaHL3/azIYWGe8IH2vHY5OZfcPMLjOzplD5yeWO2cxuMLO1ZvZ8qCyWfWtmZ/ttvGhmZxcZ83Qze8HMFpjZvWbW15cPNbOW0D6/phwxdxF3LMdExPv6jlC8y81sni+viH1tZoPN7G9mtsTMFpnZ1315RR/XO3HOpf4BLAf6dyr7GXCJn74E+KmfPhSYD/QChgEvATV+3jPARwAD/j9wki//CnCNn54M3BFh7DXAa8ABwGXAdzIsU7aYgY8CY4Dn49y3QD/gZf93bz+9dxExnwD08NM/DcU8NLxcp9eJLeYu4i75MRH1vu40/xfADyppXwODgDF+ek/gX35/VvRxvdP76M5KSXuQObkvBQaFPsylfnoqMDW03Cz/4QwCXgiVnwlcG17GT/cguCrNIor9BOBxP30Zmb/IZY2585cyjn0bXsbPuxY4s7sxd5r3KeCWrpYrR8xZ9nXJj4lS7Wv/2iuB4ZW4r0PrziT4ydCKP67Dj6polgEc8KCZzbHgF6AABjrnVgP4v/v68ky/IlXvH6sylO+wjnNuK/AmsE9EsU8Gbgs9/6pvOrgh9G9hpcUcx77N9lpR+CJBLavDMDOba2Z/N7OjQnFVSsylPiZKFfdRwBrn3Iuhsora1765ZDTwNAk7rqsluY9zzo0BTgIuMrOPdrGsZShzXZR3tU5RLLgX/gTgLl/0O+AgYBSwmuBf2q62H3vMOUQZZ6n2+feBrcAtvmg1MMQ5Nxr4FnCrme2VY/txxhzHMVGqY+VMdqy4VNS+NrM9gD8D33DObepq0W7EUPJ9XRXJ3TnX7P+uBe4l+AHvNWY2CMD/XesXz/YrUqv8dOfyHdYxsx5AH+D1CEI/CXjOObfGx7/GOdfmnGsHrvfvo9Jihnj2beS/9uU7r04BPuf8/8TOuS3OuQ1+eg5Be+rBlRJzTMdEKfZ1D+BU4I7Qe6mYfW1mPQkS+y3OuXt8cbKO6+605STpAfQG9gxNPwGcCExnx86Rn/npw9ixc+RltneOPAt8mO2dIyf78ovYsXPkzohivx34Quj5oND0N4HbKyFmdm4HLvm+JehweoWg02lvP92viJhPBBYDAzotNyAU44FAU8d24o45S9wlPyai3teh/f33StzXfhs3AVd3Kq/443qHeLv7hU7Kwx8k8/1jEfB9X74P8DDwov/bL7TO9wlqDUvxvdu+vAF43s/7Nduv8N2NoOlkGUHv+IERxL07sAHoEyr7E7AQWEDws4WDyh0zwb/Vq4FWglrHuXHtW4K28WX+8YUiY15G0NY5zz86vnif9sfNfOA54JPliLmLuGM5JqLc1778RuDCTstWxL4GjiRoClkQOh5OpsKP684P3X5ARCSFqqLNXUSk2ii5i4ikkJK7iEgKKbmLiKSQkruISAopuYuIpJCSu4hICv0v4UjvYhfAC8QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio - sigma: 4.7511068180456154e-05\n",
      "ratio: \t\t0.000862963309279242\n",
      "ratio + sigma: 0.0016784155503780278\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "sift_predictions = experiment_SIFT_matching(c_unknown_crop, l_unknown, r_unknown, predictions, discovered_ratio)\n",
    "print(sift_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(sift_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake image\n",
      "fake image\n",
      "fake image\n",
      "fake image\n",
      "fake image\n",
      "fake image\n",
      "fake image\n",
      "fake image\n",
      "fake image\n",
      "fake image\n",
      "fake image\n",
      "fake image\n"
     ]
    }
   ],
   "source": [
    "final_prediction = experiment_homography(c_unknown_crop, l_unknown, r_unknown, sift_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\t0\n",
      "0\t12\n",
      "precision: 1.0\n",
      "recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(answer, final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}